{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f822b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "train = pd.read_csv(r\"train.csv\")\n",
    "train = train.drop(columns=['id']) \n",
    "\n",
    "X = train[train.columns[~train.columns.isin(['y'])]]\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Convert categoricals to 'category'\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "y = train['y'].values\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Exhaustive LightGBM hyperparameter search\n",
    "    All parameters that affect model performance\n",
    "    \"\"\"\n",
    "\n",
    "    pos_ratio = np.mean(y)\n",
    "    neg_ratio = 1 - pos_ratio  \n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'goss']),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 200),\n",
    "        'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 0.001, 10.0, log=True),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'feature_fraction_bynode': trial.suggest_float('feature_fraction_bynode', 0.4, 1.0),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0.000001, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0.000001, 10.0, log=True),\n",
    "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0.0, 1.0),\n",
    "        'max_delta_step': trial.suggest_float('max_delta_step', 0.0, 10.0),\n",
    "        'is_unbalance': trial.suggest_categorical('is_unbalance', [True, False]),\n",
    "        'cat_smooth': trial.suggest_float('cat_smooth', 1.0, 100.0),\n",
    "        'cat_l2': trial.suggest_float('cat_l2', 0.0, 100.0),\n",
    "        'min_data_per_group': trial.suggest_int('min_data_per_group', 1, 200),\n",
    "        'max_cat_threshold': trial.suggest_int('max_cat_threshold', 1, 255),\n",
    "        'path_smooth': trial.suggest_float('path_smooth', 0.0, 10.0),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 0.001, 10.0, log=True),\n",
    "        'max_bin': trial.suggest_int('max_bin', 100, 512),\n",
    "        'histogram_pool_size': trial.suggest_float('histogram_pool_size', -1.0, 16384.0),\n",
    "        'extra_trees': trial.suggest_categorical('extra_trees', [True, False]),\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbose': -1,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    if not params['is_unbalance']:\n",
    "        params['scale_pos_weight'] = trial.suggest_float('scale_pos_weight', 3.0, 15.0) \n",
    "    \n",
    "    # Parameters for DART\n",
    "    if params['boosting_type'] == 'dart':\n",
    "        params['drop_rate'] = trial.suggest_float('drop_rate', 0.0, 0.3)\n",
    "        params['max_drop'] = trial.suggest_int('max_drop', 1, 100)\n",
    "        params['skip_drop'] = trial.suggest_float('skip_drop', 0.0, 1.0)\n",
    "        params['xgboost_dart_mode'] = trial.suggest_categorical('xgboost_dart_mode', [True, False])\n",
    "        params.pop('early_stopping_rounds')  # DART doesn't support early stopping\n",
    "    \n",
    "    # Parameters for GOSS\n",
    "    if params['boosting_type'] == 'goss':\n",
    "        params['top_rate'] = trial.suggest_float('top_rate', 0.1, 0.5)\n",
    "        params['other_rate'] = trial.suggest_float('other_rate', 0.01, 0.3)\n",
    "        # GOSS doesn't support bagging\n",
    "        params.pop('bagging_fraction', None)\n",
    "        params.pop('bagging_freq', None)\n",
    "    \n",
    "    # Constraint handling\n",
    "    if params['num_leaves'] > 2**params['max_depth']:\n",
    "        params['num_leaves'] = 2**params['max_depth'] - 1\n",
    "    \n",
    "    # 5-Fold Cross Validation with early stopping per fold\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_cv, y_val_cv = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Create LightGBM datasets\n",
    "        train_data = lgb.Dataset(\n",
    "            X_train_cv, \n",
    "            label=y_train_cv, \n",
    "            categorical_feature=categorical_cols\n",
    "        )\n",
    "        \n",
    "        val_data = lgb.Dataset(\n",
    "            X_val_cv, \n",
    "            label=y_val_cv, \n",
    "            categorical_feature=categorical_cols,\n",
    "            reference=train_data\n",
    "        )\n",
    "        \n",
    "        #Train model\n",
    "        callbacks = [lgb.log_evaluation(0), lgb.early_stopping(50)] if params['boosting_type'] != 'dart' else []\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[val_data],\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        #Predict and score\n",
    "        preds = model.predict(X_val_cv, num_iteration=model.best_iteration if params['boosting_type'] != 'dart' else None)\n",
    "        score = roc_auc_score(y_val_cv, preds)\n",
    "        cv_scores.append(score)\n",
    "        models.append(model)\n",
    "        \n",
    "        #Report intermediate value for Optuna pruning\n",
    "        intermediate_value = np.mean(cv_scores)\n",
    "        trial.report(intermediate_value, fold)\n",
    "        \n",
    "        #Prune bad trials early\n",
    "        if trial.should_prune():\n",
    "            # Clean up memory\n",
    "            del train_data, val_data, model\n",
    "            return intermediate_value\n",
    "    \n",
    "    #Store best model info for later use\n",
    "    trial.set_user_attr('cv_scores', cv_scores)\n",
    "    trial.set_user_attr('cv_std', np.std(cv_scores))\n",
    "    trial.set_user_attr('best_iteration', np.mean([m.best_iteration for m in models if hasattr(m, 'best_iteration')]))\n",
    "    \n",
    "    #Clean up memory\n",
    "    del models\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "\n",
    "# early stopping callback\n",
    "class ExhaustiveEarlyStopping:\n",
    "    def __init__(self, patience=100, min_delta=0.00001, min_trials=500):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.min_trials = min_trials\n",
    "        self.best_value = None\n",
    "        self.trials_without_improvement = 0\n",
    "        self.best_std = float('inf')\n",
    "        \n",
    "    def __call__(self, study, trial):\n",
    "        #Always run minimum trials\n",
    "        if trial.number < self.min_trials:\n",
    "            if trial.number % 100 == 0:\n",
    "                print(f\"\\n Trial {trial.number}\")\n",
    "                print(f\"   Best AUC: {study.best_value:.6f}\")\n",
    "                if 'cv_std' in study.best_trial.user_attrs:\n",
    "                    print(f\"   Best Std: {study.best_trial.user_attrs['cv_std']:.6f}\")\n",
    "            return\n",
    "        \n",
    "        current_value = trial.value\n",
    "        current_std = trial.user_attrs.get('cv_std', float('inf'))\n",
    "        \n",
    "        #Check if we have improvement (considering both mean and std)\n",
    "        has_improvement = False\n",
    "        if self.best_value is None:\n",
    "            has_improvement = True\n",
    "        elif current_value > self.best_value + self.min_delta:\n",
    "            has_improvement = True\n",
    "        elif abs(current_value - self.best_value) < self.min_delta and current_std < self.best_std:\n",
    "            has_improvement = True  # Same mean but lower variance is better\n",
    "        \n",
    "        if has_improvement:\n",
    "            self.best_value = current_value\n",
    "            self.best_std = current_std\n",
    "            self.trials_without_improvement = 0\n",
    "            print(f\"\\n Trial {trial.number}: New best = {current_value:.6f} (std: {current_std:.6f})\")\n",
    "        else:\n",
    "            self.trials_without_improvement += 1\n",
    "        \n",
    "        #Progress every 100 trials\n",
    "        if trial.number % 100 == 0:\n",
    "            print(f\"\\n Progress Report - Trial {trial.number}\")\n",
    "            print(f\"   Current: {current_value:.6f} (std: {current_std:.6f})\")\n",
    "            print(f\"   Best: {self.best_value:.6f} (std: {self.best_std:.6f})\")\n",
    "            print(f\"   No improvement for: {self.trials_without_improvement} trials\")\n",
    "            print(f\"   Boosting type: {trial.params.get('boosting_type', 'gbdt')}\")\n",
    "        \n",
    "        #Stop if no improvement\n",
    "        if self.trials_without_improvement >= self.patience:\n",
    "            print(f\"\\n Early stopping triggered at trial {trial.number}\")\n",
    "            print(f\"   No improvement for {self.patience} trials\")\n",
    "            print(f\"   Final best AUC: {study.best_value:.6f}\")\n",
    "            study.stop()\n",
    "\n",
    "\n",
    "#Create and run the study\n",
    "print(\"Starting EXHAUSTIVE LightGBM hyperparameter optimization\")\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Categorical features: {len(categorical_cols)}\")\n",
    "print(f\"Numerical features: {len(numerical_cols)}\")\n",
    "print(f\"Target distribution: {np.mean(y):.2%} positive class\\n\")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=TPESampler(\n",
    "        n_startup_trials=500, \n",
    "        n_ei_candidates=100,  \n",
    "        seed=42\n",
    "    ),\n",
    "    pruner=MedianPruner(\n",
    "        n_startup_trials=100,\n",
    "        n_warmup_steps=2,\n",
    "        interval_steps=1\n",
    "    )\n",
    ")\n",
    "\n",
    "#Set up callbacks\n",
    "early_stopping = ExhaustiveEarlyStopping(\n",
    "    patience=150, \n",
    "    min_delta=0.00001,\n",
    "    min_trials=1000  \n",
    ")\n",
    "\n",
    "#Run optimization\n",
    "print(\"This will take several hours for exhaustive search...\\n\")\n",
    "\n",
    "try:\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=10000,  \n",
    "        callbacks=[early_stopping],\n",
    "        gc_after_trial=True,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n Optimization interrupted by user\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMIZATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTrials completed: {len(study.trials)}\")\n",
    "print(f\"Best ROC-AUC Score: {study.best_value:.6f}\")\n",
    "if 'cv_std' in study.best_trial.user_attrs:\n",
    "    print(f\"Cross-validation Std: {study.best_trial.user_attrs['cv_std']:.6f}\")\n",
    "if 'best_iteration' in study.best_trial.user_attrs:\n",
    "    print(f\"Average best iteration: {study.best_trial.user_attrs['best_iteration']:.0f}\")\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "for key, value in sorted(study.best_params.items()):\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "#Feature importance from best model\n",
    "print(\"\\n Training final model on full training data...\")\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "})\n",
    "\n",
    "#Extract n_estimators for num_boost_round and remove it from params\n",
    "#lgb.train uses num_boost_round, not n_estimators\n",
    "num_boost_round = best_params.pop('n_estimators')\n",
    "print(f\"   Using {num_boost_round} boosting rounds\")\n",
    "\n",
    "final_train_data = lgb.Dataset(X, label=y, categorical_feature=categorical_cols)\n",
    "final_model = lgb.train(\n",
    "    best_params,\n",
    "    final_train_data,\n",
    "    num_boost_round=num_boost_round\n",
    ")\n",
    "# Save everything\n",
    "print(\"\\n Saving results...\")\n",
    "final_model.save_model('best_lgbm_model.txt')\n",
    "study.trials_dataframe().to_csv('optuna_trials.csv', index=False)\n",
    "pd.DataFrame([study.best_params]).to_json('best_params.json')\n",
    "\n",
    "print(\"\\n Exhaustive optimization complete!\")\n",
    "print(f\"   Model saved to: best_lgbm_model.txt\")\n",
    "print(f\"   Trials saved to: optuna_trials.csv\")\n",
    "print(f\"   Best params saved to: best_params.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b9c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "test = pd.read_csv(r\"test.csv\")\n",
    "train = pd.read_csv(r\"train.csv\")\n",
    "\n",
    "#Save test IDs for later\n",
    "test_ids = test['id'].copy()\n",
    "test = test.drop(columns=['id'])\n",
    "train = train.drop(columns=['id'])\n",
    "\n",
    "X = train[train.columns[~train.columns.isin(['y'])]]\n",
    "y = train['y'].values\n",
    "\n",
    "#Identify column types\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "#Convert categoricals to 'category' dtype for LightGBM\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "#Best parameters from Trial\n",
    "best_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 2640,\n",
    "    'learning_rate': 0.021647242130854016,\n",
    "    'num_leaves': 148,\n",
    "    'max_depth': 10,\n",
    "    'min_data_in_leaf': 12,\n",
    "    'min_sum_hessian_in_leaf': 0.003246887228497265,\n",
    "    'bagging_fraction': 0.8593280503095165,\n",
    "    'bagging_freq': 0,\n",
    "    'feature_fraction': 0.6499394970893753,\n",
    "    'feature_fraction_bynode': 0.713506108651353,\n",
    "    'lambda_l1': 2.412353452746242e-06,\n",
    "    'lambda_l2': 6.479584245641202,\n",
    "    'min_gain_to_split': 0.22612533124967193,\n",
    "    'max_delta_step': 3.0419871963628085,\n",
    "    'is_unbalance': True,\n",
    "    'cat_smooth': 1.1459083865448303,\n",
    "    'cat_l2': 72.93447940879963,\n",
    "    'min_data_per_group': 194,\n",
    "    'max_cat_threshold': 58,\n",
    "    'path_smooth': 6.630471918034225,\n",
    "    'min_child_weight': 0.9280797735870648,\n",
    "    'max_bin': 450,\n",
    "    'histogram_pool_size': 6923.779393067985,\n",
    "    'extra_trees': False,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "\n",
    "print(\"STEP 1: VERIFY CV SCORE WITH SAME STRATEGY AS OPTIMIZATION\")\n",
    "num_boost_round = best_params.pop('n_estimators')\n",
    "\n",
    "# Replicate same CV strategy used during optimization\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "cv_best_iterations = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_cv, y_val_cv = y[train_idx], y[val_idx]\n",
    "    \n",
    "    train_data = lgb.Dataset(\n",
    "        X_train_cv, \n",
    "        label=y_train_cv, \n",
    "        categorical_feature=categorical_cols\n",
    "    )\n",
    "    val_data = lgb.Dataset(\n",
    "        X_val_cv, \n",
    "        label=y_val_cv, \n",
    "        categorical_feature=categorical_cols,\n",
    "        reference=train_data\n",
    "    )\n",
    "    model = lgb.train(\n",
    "        best_params,\n",
    "        train_data,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[val_data],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(50),\n",
    "            lgb.log_evaluation(0)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    #Store best iteration\n",
    "    cv_best_iterations.append(model.best_iteration)\n",
    "    \n",
    "    #Evaluate\n",
    "    val_pred = model.predict(X_val_cv, num_iteration=model.best_iteration)\n",
    "    score = roc_auc_score(y_val_cv, val_pred)\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    print(f\"Fold {fold}: AUC = {score:.6f} (best_iteration: {model.best_iteration})\")\n",
    "\n",
    "#Calculate and display CV results\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "mean_best_iter = np.mean(cv_best_iterations)\n",
    "\n",
    "print(f\"\\nCV Results:\")\n",
    "print(f\"  Mean AUC: {mean_cv_score:.6f} (std: {std_cv_score:.6f})\")\n",
    "print(f\"  Average best iteration: {mean_best_iter:.0f} (out of {num_boost_round})\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: TRAIN FINAL MODEL WITH VALIDATION SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create hold-out validation set for final model training\n",
    "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train_final.shape}\")\n",
    "print(f\"Validation set: {X_val_final.shape}\")\n",
    "\n",
    "# Create datasets for final model\n",
    "train_data_final = lgb.Dataset(\n",
    "    X_train_final, \n",
    "    label=y_train_final, \n",
    "    categorical_feature=categorical_cols\n",
    ")\n",
    "val_data_final = lgb.Dataset(\n",
    "    X_val_final, \n",
    "    label=y_val_final, \n",
    "    categorical_feature=categorical_cols,\n",
    "    reference=train_data_final\n",
    ")\n",
    "\n",
    "# Train final model with early stopping\n",
    "print(f\"\\nTraining final model with early stopping...\")\n",
    "print(f\"Max rounds: {num_boost_round}\")\n",
    "print(f\"Early stopping patience: 50 rounds\\n\")\n",
    "\n",
    "final_model = lgb.train(\n",
    "    best_params,\n",
    "    train_data_final,\n",
    "    num_boost_round=num_boost_round,\n",
    "    valid_sets=[train_data_final, val_data_final],\n",
    "    valid_names=['train', 'valid'],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(50),\n",
    "        lgb.log_evaluation(100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal model stopped at iteration: {final_model.best_iteration}\")\n",
    "\n",
    "# Evaluate final model\n",
    "train_pred_final = final_model.predict(X_train_final, num_iteration=final_model.best_iteration)\n",
    "val_pred_final = final_model.predict(X_val_final, num_iteration=final_model.best_iteration)\n",
    "\n",
    "train_auc_final = roc_auc_score(y_train_final, train_pred_final)\n",
    "val_auc_final = roc_auc_score(y_val_final, val_pred_final)\n",
    "\n",
    "print(f\"Final Model Performance:\")\n",
    "print(f\"Training AUC: {train_auc_final:.6f}\")\n",
    "print(f\"Validation AUC: {val_auc_final:.6f}\")\n",
    "print(f\"Gap (overfitting indicator): {(train_auc_final - val_auc_final):.6f}\")\n",
    "\n",
    "#Use average best iteration from CV with safety margin\n",
    "optimal_iterations = int(mean_best_iter * 1.1)  # Add 10% safety margin\n",
    "print(f\"Using {optimal_iterations} iterations (CV average: {mean_best_iter:.0f} + 10% margin)\")\n",
    "\n",
    "#Train on full dataset with optimal iterations\n",
    "full_train_data = lgb.Dataset(X, label=y, categorical_feature=categorical_cols)\n",
    "\n",
    "final_model_full = lgb.train(\n",
    "    best_params,\n",
    "    full_train_data,\n",
    "    num_boost_round=optimal_iterations\n",
    ")\n",
    "\n",
    "print(f\"Model trained on full data with {optimal_iterations} iterations\")\n",
    "\n",
    "# Check training performance (will be optimistic)\n",
    "full_train_pred = final_model_full.predict(X)\n",
    "full_train_auc = roc_auc_score(y, full_train_pred)\n",
    "print(f\"Full training AUC (optimistic): {full_train_auc:.6f}\")\n",
    "\n",
    "\n",
    "print(\"STEP 4: FEATURE IMPORTANCE ANALYSIS\")\n",
    "\n",
    "\n",
    "#Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance_split': final_model_full.feature_importance(importance_type='split'),\n",
    "    'importance_gain': final_model_full.feature_importance(importance_type='gain')\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values('importance_gain', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features (by gain)\")\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"  {row['feature']:30s} Gain: {row['importance_gain']:8.0f}  Split: {row['importance_split']:5.0f}\")\n",
    "\n",
    "\n",
    "print(\"STEP 5: MAKE TEST PREDICTIONS\")\n",
    "\n",
    "\n",
    "#Prepare test data\n",
    "test_categorical_cols = [col for col in categorical_cols if col in test.columns]\n",
    "for col in test_categorical_cols:\n",
    "    test[col] = test[col].astype('category')\n",
    "\n",
    "#Make predictions using the full data model with optimal iterations\n",
    "test_probs = final_model_full.predict(test)\n",
    "\n",
    "print(f\"Test predictions shape: {test_probs.shape}\")\n",
    "print(f\"Test probability range: [{test_probs.min():.6f}, {test_probs.max():.6f}]\")\n",
    "print(f\"Test probability mean: {test_probs.mean():.6f}\")\n",
    "\n",
    "#Convert to binary predictions\n",
    "threshold = 0.5\n",
    "\n",
    "\n",
    "print(f\"\\nBinary predictions distribution:\")\n",
    "\n",
    "#Compare with training distribution\n",
    "print(f\"\\nTraining distribution:\")\n",
    "print(f\"  Class 0: {sum(y==0):5d} samples ({sum(y==0)/len(y)*100:5.1f}%)\")\n",
    "print(f\"  Class 1: {sum(y==1):5d} samples ({sum(y==1)/len(y)*100:5.1f}%)\")\n",
    "\n",
    "\n",
    "print(\"STEP 6: SAVE EVERYTHING\")\n",
    "\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'y': test_probs\n",
    "})\n",
    "submission.to_csv('submission_final.csv', index=False)\n",
    "print(f\"Submission saved: submission_final.csv\")\n",
    "\n",
    "# Save probability analysis\n",
    "prob_analysis = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'probability': test_probs,\n",
    "})\n",
    "prob_analysis.to_csv('test_probabilities_analysis.csv', index=False)\n",
    "print(f\"Probability analysis saved: test_probabilities_analysis.csv\")\n",
    "\n",
    "# Save model\n",
    "final_model_full.save_model('final_lgbm_model_optimized.txt')\n",
    "print(f\"Model saved: final_lgbm_model_optimized.txt\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance.to_csv('feature_importance_final.csv', index=False)\n",
    "print(f\"Feature importance saved: feature_importance_final.csv\")\n",
    "\n",
    "# Save training report\n",
    "report = {\n",
    "    'cv_mean_score': float(mean_cv_score),\n",
    "    'cv_std_score': float(std_cv_score),\n",
    "    'cv_best_iterations': cv_best_iterations,\n",
    "    'mean_best_iteration': float(mean_best_iter),\n",
    "    'final_iterations_used': optimal_iterations,\n",
    "    'validation_auc': float(val_auc_final),\n",
    "    'full_train_auc': float(full_train_auc),\n",
    "    'test_prob_mean': float(test_probs.mean()),\n",
    "    'test_prob_std': float(test_probs.std()),\n",
    "    'parameters': best_params\n",
    "}\n",
    "\n",
    "with open('training_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "print(f\"Training report saved: training_report.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
